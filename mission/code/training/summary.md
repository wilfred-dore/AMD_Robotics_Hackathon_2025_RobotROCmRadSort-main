# ğŸ† Mission 2: Nuclear Waste Sorting with SmolVLA

## Team 8 - AMD Hackathon Submission

---

## ğŸ¯ Objective

Sort simulated radioactive waste (3 different colored highlighters: **Pink**, **Yellow**, **Green**) into corresponding boxes using a **SO-101** robot controlled by a **SmolVLA** (Vision-Language-Action) model.

**Why SmolVLA?**
- Understands natural language instructions ("Pick the pink nuclear rod")
- Fully leverages **AMD MI300X** computing power
- State-of-the-art in VLA robotics

---

## ğŸ“Š Collected Dataset

| Parameter | Value |
|-----------|-------|
| **Repo ID** | `Gowshigan/mission2-nuclear-sorting-combined` |
| **Total Episodes** | 60 |
| **Episodes per color** | 20 (Yellow, Pink, Green) |
| **FPS** | 30 |
| **Resolution** | 640x480 |
| **Robot** | SO-101 Follower |
| **Teleoperation** | SO-101 Leader |

### Defined Tasks:
1. `Sort Yellow to Green Box`
2. `Sort Pink to Yellow Box`
3. `Sort Green to Pink Box`

### Camera Configuration:
- **Front Camera** (index 2): Global workspace view
- **Wrist Camera** (index 4): Gripper view for precision

---

## ğŸ¤– Models Trained on AMD MI300X

| Model | Steps | Batch Size | Final Loss | Status | HuggingFace Hub |
|-------|-------|------------|------------|--------|-----------------|
| SmolVLA 15k | 15,000 | 8 | ~0.02 | âœ… Done | `Gowshigan/smolvla_mission2_15k` |
| SmolVLA 20k | 20,000 | 4 | ~0.015 | âœ… Done | `Gowshigan/smolvla_mission2_20k` |
| SmolVLA 50k | 50,000 | 4 | - | ğŸ”„ In Progress | - |
| SmolVLA 200k | 200,000 | 32 | - | ğŸ”„ In Progress | - |

### Training Hyperparameters:
```yaml
policy.type: smolvla
optimizer.lr: 0.0001
scheduler.warmup_steps: 1000
scheduler.decay_steps: 30000
dataset.image_transforms.enable: true
wandb.project: mission2-smolvla
save_freq: 10000  # Checkpoint every 10k steps
```

---

## ğŸ”§ Issues Resolved

### 1. `ValueError: Task cannot be None` on MI300X

**Cause:** Incorrect `tasks.parquet` format when loading dataset.

**Solution:**
```bash
sed -i 's/self.meta.tasks.iloc\[task_idx\].name/self.meta.tasks.iloc[task_idx]["task"]/' /workspace/lerobot/src/lerobot/datasets/lerobot_dataset.py
```

### 2. `FileExistsError: Output directory already exists`

**Solution:** Delete folder before restarting or use `--resume=true`
```bash
rm -rf outputs/train/smolvla_*
```

### 3. Cameras freezing during inference

**Causes:** USB bandwidth saturated with 2 cameras

**Applied Solutions:**
```bash
# Increase USB buffer
echo 1000 | sudo tee /sys/module/usbcore/parameters/usbfs_memory_mb

# Disable autofocus (reduces lag)
v4l2-ctl -d /dev/video2 --set-ctrl=focus_automatic_continuous=0
v4l2-ctl -d /dev/video4 --set-ctrl=focus_automatic_continuous=0
```

### 4. Feature Mismatch with `smolvla_base`

**Problem:** Pre-trained model expected 3 cameras, our dataset has 2.

**Solution:** Train from scratch with `--policy.type=smolvla` instead of fine-tuning from `--policy.path=lerobot/smolvla_base`

---

## ğŸ“ Created Scripts

### 1. `test_smolvla_policy.sh` - Inference Testing
```bash
#!/bin/bash
# Usage: ./test_smolvla_policy.sh [policy] [task] [n_action_steps] [episode_time] [num_episodes]

# Examples:
./test_smolvla_policy.sh  # Default: 15k model
./test_smolvla_policy.sh Gowshigan/smolvla_mission2_20k "Sort Pink to Yellow Box"
./test_smolvla_policy.sh Gowshigan/smolvla_mission2_15k "Sort Yellow to Green Box" 10 60 3
```

### 2. MI300X Training Command
```python
# Jupyter Notebook on MI300X
!rm -rf outputs/train/smolvla_200k
!sed -i 's/self.meta.tasks.iloc\[task_idx\].name/self.meta.tasks.iloc[task_idx]["task"]/' /workspace/lerobot/src/lerobot/datasets/lerobot_dataset.py

!lerobot-train \
  --policy.type=smolvla \
  --dataset.repo_id=Gowshigan/mission2-nuclear-sorting-combined \
  --batch_size=32 \
  --steps=200000 \
  --save_freq=10000 \
  --output_dir=outputs/train/smolvla_200k \
  --job_name=smolvla_200k \
  --policy.device=cuda \
  --dataset.image_transforms.enable=true \
  --wandb.enable=true \
  --wandb.project=mission2-smolvla
```

### 3. `collect_curriculum_data.py` - Additional Data Collection
Script for collecting simple movements (curriculum learning).

---

## ğŸ“ˆ W&B Tracking

- **Project:** `mission2-smolvla`
- **URL:** https://wandb.ai/gowshigan-upec/mission2-smolvla

---

## ğŸš€ Technical Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     SmolVLA Pipeline                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ Front    â”‚â”€â”€â”€â”€â–¶â”‚          â”‚     â”‚                      â”‚â”‚
â”‚  â”‚ Camera   â”‚     â”‚  SmolVLA â”‚â”€â”€â”€â”€â–¶â”‚  Action (6 DOF)      â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  Model   â”‚     â”‚  - shoulder_pan      â”‚â”‚
â”‚                   â”‚          â”‚     â”‚  - shoulder_lift     â”‚â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚ (VLM +   â”‚     â”‚  - elbow_flex        â”‚â”‚
â”‚  â”‚ Wrist    â”‚â”€â”€â”€â”€â–¶â”‚ Diffusionâ”‚     â”‚  - wrist_flex        â”‚â”‚
â”‚  â”‚ Camera   â”‚     â”‚  Expert) â”‚     â”‚  - wrist_roll        â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚          â”‚     â”‚  - gripper           â”‚â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â–²                                  â”‚
â”‚  â”‚ Task     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚
â”‚  â”‚ Prompt   â”‚  "Sort Yellow to Green Box"                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¬ Test Results

### Observations:
- **15k model:** Robot moves and shows basic task understanding
- **20k model:** Smoother movements, but precision needs improvement
- **n_action_steps=50:** Action chunk predicted, may cause delay if environment changes
- **n_action_steps=10:** More reactive to changes

### Possible Improvements:
1. More data (>100 episodes)
2. More steps (200k+)
3. More aggressive data augmentation
4. Curriculum learning (simple â†’ complex movements)

---

## ğŸ“¦ Project Files

```
lerobot/
â”œâ”€â”€ MISSION2_HACKATHON_SUMMARY.md     # This document
â”œâ”€â”€ test_smolvla_policy.sh            # Test script
â”œâ”€â”€ train_smolvla_optimized.sh        # Multi-config training
â”œâ”€â”€ collect_curriculum_data.py        # Curriculum collection
â”œâ”€â”€ sweep_smolvla.yaml               # W&B sweep config
â””â”€â”€ src/lerobot/scripts/
    â”œâ”€â”€ merge_mission2_data.py        # Dataset merging
    â”œâ”€â”€ detect_stabilos.py            # Color detection
    â””â”€â”€ test_color_isolation.py       # Color isolation testing
```

---

## ğŸ Conclusion

**What we accomplished:**
- âœ… Collected 60 episodes of sorting data
- âœ… Trained multiple SmolVLA models (15k, 20k, 50k, 200k in progress)
- âœ… Tested on physical SO-101 robot
- âœ… Resolved all dataset/model compatibility bugs
- âœ… Created reusable scripts

**Lessons learned:**
- SmolVLA requires significant data and training steps for complex tasks
- Camera quality directly impacts performance
- Fine-tuning from `smolvla_base` requires matching camera count

**Next steps:**
1. Complete 200k training
2. Test intermediate checkpoints (50k, 100k, 150k)
3. Final demo on robot

---

## ğŸ‘¥ Team

**Team 8**
- Robot: SO-101 
- Cloud GPU: AMD MI300X
- Framework: LeRobot + SmolVLA
- Hackathon: AMD Hackathon 2025

---


